{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Get the params of the created redshift cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "KEY=config.get('AWS','KEY')\n",
    "SECRET= config.get('AWS','SECRET')\n",
    "DWH_DB= config.get(\"CLUSTER\",\"DB_NAME\")\n",
    "DWH_ENDPOINT = config.get('CLUSTER', 'END_POINT')\n",
    "DWH_DB_USER= config.get(\"CLUSTER\",\"DB_USER\")\n",
    "DWH_DB_PASSWORD= config.get(\"CLUSTER\",\"DB_PASSWORD\")\n",
    "DWH_PORT = config.get(\"CLUSTER\",\"DB_PORT\")\n",
    "DWH_ROLE_ARN = config.get(\"IAM_ROLE\", \"ARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Connect to the Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Create Staging Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "DROP TABLE IF EXISTS staging_songs;\n",
    "CREATE TABLE \"staging_songs\" (\n",
    "    \"num_songs\" INTEGER ,\n",
    "    \"artist_id\" VARCHAR(60),\n",
    "    \"artist_latitude\" VARCHAR(50),\n",
    "    \"artist_longitude\" VARCHAR(50),\n",
    "    \"artist_location\" VARCHAR(200),\n",
    "    \"artist_name\" VARCHAR(100),\n",
    "    \"song_id\" VARCHAR(60),\n",
    "    \"title\" VARCHAR(200),\n",
    "    \"duration\" numeric(10,5),\n",
    "    \"year\" INTEGER\n",
    ");\n",
    "\n",
    "DROP TABLE IF EXISTS staging_events;\n",
    "CREATE TABLE \"staging_events\" (\n",
    "    \"artist\" VARCHAR(200),\n",
    "    \"auth\" VARCHAR(12),\n",
    "    \"firstName\" VARCHAR(30),\n",
    "    \"gender\" VARCHAR(1),\n",
    "    \"itemInSession\" SMALLINT,\n",
    "    \"lastName\" VARCHAR(30),\n",
    "    \"length\" numeric(10,5),\n",
    "    \"level\" VARCHAR(6),\n",
    "    \"location\" VARCHAR(300), \n",
    "    \"method\" VARCHAR(3),\n",
    "    \"page\" VARCHAR(20),\n",
    "    \"registeration\" DECIMAL,\n",
    "    \"sessionId\" BIGINT,\n",
    "    \"song\" VARCHAR(300),\n",
    "    \"status\" VARCHAR(4),\n",
    "    \"ts\" BIGINT,\n",
    "    \"userAgent\" VARCHAR(300),\n",
    "    \"userId\" INTEGER\n",
    "\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Write ETL to copy data from JSON files in S3 to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "song_data = config.get('S3','SONG_DATA')\n",
    "qry = \"\"\"\n",
    "    copy staging_songs from {}\n",
    "    credentials 'aws_iam_role={}'\n",
    "    format as json 'auto' compupdate off STATUPDATE ON TRUNCATECOLUMNS region 'us-west-2';\n",
    "\"\"\".format(song_data, DWH_ROLE_ARN)\n",
    "\n",
    "%sql $qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log_data = config.get('S3','LOG_DATA')\n",
    "log_json_path = config.get('S3', 'LOG_JSONPATH')\n",
    "qry = \"\"\"\n",
    "    copy staging_events from {}\n",
    "    credentials 'aws_iam_role={}'\n",
    "    format as json {} compupdate off TRUNCATECOLUMNS region 'us-west-2';\n",
    "\"\"\".format(log_data, DWH_ROLE_ARN, log_json_path)\n",
    "\n",
    "%sql $qry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Create Analytics Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "DROP TABLE IF EXISTS songplays;\n",
    "DROP TABLE IF EXISTS users;\n",
    "DROP TABLE IF EXISTS songs;\n",
    "DROP TABLE IF EXISTS artists;\n",
    "DROP TABLE IF EXISTS times;\n",
    "\n",
    "CREATE TABLE songs \n",
    "(\n",
    "    song_id VARCHAR PRIMARY KEY NOT NULL sortkey distkey,\n",
    "    title VARCHAR,\n",
    "    artist_id VARCHAR,\n",
    "    year INTEGER,\n",
    "    duration numeric(10,5)\n",
    ");\n",
    "\n",
    "CREATE TABLE artists \n",
    "(\n",
    "    artist_id VARCHAR PRIMARY KEY NOT NULL sortkey,\n",
    "    name VARCHAR,\n",
    "    location VARCHAR, \n",
    "    lattitude VARCHAR,\n",
    "    longitude VARCHAR\n",
    ");\n",
    "\n",
    "CREATE TABLE songplays \n",
    "(\n",
    "    songplay_id INTEGER IDENTITY(0,1) PRIMARY KEY,\n",
    "    start_time TIMESTAMP NOT NULL,\n",
    "    user_id INTEGER NOT NULL,\n",
    "    level VARCHAR,\n",
    "    song_id VARCHAR distkey, \n",
    "    artist_id VARCHAR sortkey,\n",
    "    session_id INTEGER,\n",
    "    location VARCHAR,\n",
    "    user_agent VARCHAR\n",
    ");\n",
    "\n",
    "CREATE TABLE users \n",
    "(\n",
    "    user_id INTEGER PRIMARY KEY NOT NULL sortkey,\n",
    "    first_name VARCHAR,\n",
    "    last_name VARCHAR,\n",
    "    gender VARCHAR,\n",
    "    level VARCHAR\n",
    ");\n",
    "\n",
    "CREATE TABLE times \n",
    "(\n",
    "    starttime TIMESTAMP PRIMARY KEY NOT NULL sortkey,\n",
    "    hour INTEGER,\n",
    "    day INTEGER,\n",
    "    week INTEGER,\n",
    "    month INTEGER,\n",
    "    year INTEGER,\n",
    "    weekday INTEGER\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6: Insert from staging tables into analytics tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "qry = \"\"\"\n",
    "    INSERT INTO times\n",
    "    SELECT \n",
    "        distinct starttime,\n",
    "        EXTRACT(hour from starttime) as hour,\n",
    "        EXTRACT(day from starttime) as day,\n",
    "        EXTRACT(week from starttime) as week,\n",
    "        EXTRACT(month from starttime) as month,\n",
    "        EXTRACT(year from starttime) as year,\n",
    "        EXTRACT(weekday from starttime) as weekday \n",
    "        FROM   \n",
    "            (SELECT TIMESTAMP 'epoch' + e.ts/1000 * interval '1 second' AS starttime\n",
    "            FROM staging_events e)\n",
    "     \"\"\"\n",
    "\n",
    "%sql $qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "qry = \"\"\"\n",
    "    INSERT INTO users\n",
    "    SELECT \n",
    "        DISTINCT userId,\n",
    "        firstName,\n",
    "        lastName,\n",
    "        gender,\n",
    "        level FROM staging_events where page != 'NextSong' \n",
    "        AND userID is not NULL\"\"\"\n",
    "\n",
    "%sql $qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "qry = \"\"\"\n",
    "    INSERT INTO artists\n",
    "    SELECT \n",
    "        DISTINCT artist_id,\n",
    "        artist_name,\n",
    "        artist_location,\n",
    "        artist_latitude,\n",
    "        artist_longitude FROM staging_songs where artist_id is not null \"\"\"\n",
    "\n",
    "%sql $qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "qry = \"\"\"\n",
    "    INSERT INTO songs\n",
    "    SELECT \n",
    "        DISTINCT song_id,\n",
    "        title,\n",
    "        artist_id,\n",
    "        year,\n",
    "        duration FROM staging_songs where song_id is not null\"\"\"\n",
    "\n",
    "%sql $qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "qry = \"\"\"\n",
    "    INSERT INTO songplays (start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
    "    SELECT \n",
    "        TIMESTAMP 'epoch' + e.ts/1000 * interval '1 second' AS starttime,\n",
    "        userId,\n",
    "        level,\n",
    "        song_id,\n",
    "        artist_id,\n",
    "        sessionId,\n",
    "        location,\n",
    "        userAgent\n",
    "        FROM staging_songs s JOIN staging_events e\n",
    "        ON s.artist_name = e.artist \n",
    "        AND s.title = e.song\n",
    "        AND e.length = s.duration\n",
    "        WHERE e.page ='NextSong' \"\"\"\n",
    "\n",
    "%sql $qry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
